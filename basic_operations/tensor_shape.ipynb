{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `view()`, `reshape()`, `transpose()`, `permute()`\n",
    "\n",
    "\n",
    "[Discussion of `contiguous`](https://stackoverflow.com/questions/26998223/what-is-the-difference-between-contiguous-and-non-contiguous-arrays/26999092#26999092)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor = torch.rand(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7871, 0.4773, 0.6763, 0.4647, 0.8857, 0.6221, 0.6647, 0.2766, 0.5620,\n",
       "        0.4554, 0.6573, 0.7052])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7871, 0.4773, 0.6763, 0.4647],\n",
       "        [0.8857, 0.6221, 0.6647, 0.2766],\n",
       "        [0.5620, 0.4554, 0.6573, 0.7052]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tensor.view(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7871, 0.4773, 0.6763, 0.4647],\n",
       "        [0.8857, 0.6221, 0.6647, 0.2766],\n",
       "        [0.5620, 0.4554, 0.6573, 0.7052]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tensor.reshape(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `reshape()` vs `view()`\n",
    "\n",
    "`reshape` tries to return a `view` if possible, otherwise copies to data to a contiguous tensor and returns the `view` on it. ([Source](https://discuss.pytorch.org/t/difference-between-view-reshape-and-permute/54157/2))\n",
    "\n",
    "`view()` works on contiguous tensors and `reshape()` works on non-contugous tensors (`contiguous()` + `view()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).view(4, 3)\n",
    "\n",
    "# View works on contiguous tensors\n",
    "print(x.is_contiguous())\n",
    "print(x)\n",
    "print(x.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  3,  6,  9],\n",
      "        [ 1,  4,  7, 10],\n",
      "        [ 2,  5,  8, 11]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "y = x.permute(1, 0)\n",
    "\n",
    "# Reshape works on non-contugous tensors (contiguous() + view)\n",
    "print(y)\n",
    "print(y.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(y.view(-1))\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  3,  6,  9,  1,  4,  7, 10,  2,  5,  8, 11])\n",
      "tensor([ 0,  3,  6,  9,  1,  4,  7, 10,  2,  5,  8, 11])\n"
     ]
    }
   ],
   "source": [
    "print(y.reshape(-1))\n",
    "print(y.contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage of `view` and `reshape` does not depend on training / not-training.\n",
    "I personally use `view` whenever possible and add a `contiguous` call to it, if necessary. This will make sure I see, where a copy is done in my code. `reshape` on the other hand does this automatically, so your code might look cleaner. [Source](https://discuss.pytorch.org/t/difference-between-view-reshape-and-permute/54157/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `transpose()` vs `permute()` vs `swapaxes()`\n",
    "\n",
    "`sawpaxes()` is an alias for `transpose()`. This function is equivalent to NumPyâ€™s swapaxes function. [Source](https://pytorch.org/docs/stable/generated/torch.swapaxes.html#torch.swapaxes)\n",
    "\n",
    "`permute()` and `tranpose()` are similar. `transpose()` can only swap two dimension. But `permute()` can swap all the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.4428, 0.1552, 0.6599, 0.4228],\n",
       "          [0.1577, 0.7957, 0.0523, 0.4348],\n",
       "          [0.8402, 0.3298, 0.9236, 0.4066]],\n",
       " \n",
       "         [[0.5747, 0.8458, 0.0487, 0.9425],\n",
       "          [0.5154, 0.4294, 0.5961, 0.0803],\n",
       "          [0.7357, 0.1801, 0.9983, 0.0248]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.4428, 0.5747],\n",
       "          [0.1577, 0.5154],\n",
       "          [0.8402, 0.7357]],\n",
       " \n",
       "         [[0.1552, 0.8458],\n",
       "          [0.7957, 0.4294],\n",
       "          [0.3298, 0.1801]],\n",
       " \n",
       "         [[0.6599, 0.0487],\n",
       "          [0.0523, 0.5961],\n",
       "          [0.9236, 0.9983]],\n",
       " \n",
       "         [[0.4228, 0.9425],\n",
       "          [0.4348, 0.0803],\n",
       "          [0.4066, 0.0248]]]),\n",
       " torch.Size([4, 3, 2]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(0, 2), x.transpose(0, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.4428, 0.5747],\n",
       "          [0.1577, 0.5154],\n",
       "          [0.8402, 0.7357]],\n",
       " \n",
       "         [[0.1552, 0.8458],\n",
       "          [0.7957, 0.4294],\n",
       "          [0.3298, 0.1801]],\n",
       " \n",
       "         [[0.6599, 0.0487],\n",
       "          [0.0523, 0.5961],\n",
       "          [0.9236, 0.9983]],\n",
       " \n",
       "         [[0.4228, 0.9425],\n",
       "          [0.4348, 0.0803],\n",
       "          [0.4066, 0.0248]]]),\n",
       " torch.Size([4, 3, 2]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.swapaxes(0, 2), x.swapaxes(0, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.permute(2, 1, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x.transpose(0, 2) == x.permute(2, 1, 0)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x.transpose(0, 2) == x.swapaxes(0, 2)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x.transpose(0, 2) == x.transpose(2, 0)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, in `permute()`, you must provide the new order of all the dimensions. In `transpose()`, you can only provide two dimensions. `tranpose()` can be thought as a special case of `permute()` method in for 2D tensors."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6810982191895c2ebaaa2d7a4aa6e780e2483024285fad22c3a0d3dd1a161e35"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
