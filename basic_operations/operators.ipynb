{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Tensor Operation\n",
    "\n",
    "Including: `sum()`, `mean()`, `prod()`, `sqrt()`, etc\n",
    "\n",
    "Inplace Operation: add `_` to the function name, e.g. `sum_()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_t = torch.randn(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8361, -0.4165, -0.0693,  0.0925],\n",
       "        [ 0.2939, -1.1079, -0.3846, -0.5302],\n",
       "        [-1.7553,  0.8901,  2.4044, -1.0195]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.7663), tensor(-0.0639))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t.sum(), sample_t.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinlge operation will reduce dimension.\n",
    "\n",
    "To keep dimension, set `keepdim=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6253, -0.6343,  1.9505, -1.4572])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "_ = sample_t.sum(0)\n",
    "\n",
    "print(_)\n",
    "print(_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6253, -0.6343,  1.9505, -1.4572]])\n",
      "torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "_ = sample_t.sum(0, keepdim=True)\n",
    "\n",
    "print(_)\n",
    "print(_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8361, -0.4165, -0.0693,  0.0925],\n",
       "        [ 0.2939, -1.1079, -0.3846, -0.5302],\n",
       "        [-1.7553,  0.8901,  2.4044, -1.0195]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inplace operations only work for ones that doesn't change tensor shape like `sqrt_()` but not `sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Tensor' object has no attribute 'sum_'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sample_t.sum_()\n",
    "except AttributeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9144,    nan,    nan, 0.3041],\n",
       "        [0.5421,    nan,    nan,    nan],\n",
       "        [   nan, 0.9434, 1.5506,    nan]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t.sqrt_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9144,    nan,    nan, 0.3041],\n",
       "        [0.5421,    nan,    nan,    nan],\n",
       "        [   nan, 0.9434, 1.5506,    nan]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple-tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_t1 = torch.randn(2, 3)\n",
    "sample_t2 = torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1205,  0.9371,  1.8299],\n",
      "        [-0.2666, -0.8590, -0.4210]])\n",
      "tensor([[ 0.5028,  0.5248, -1.1740],\n",
      "        [-0.0944, -0.0601, -0.4540]])\n"
     ]
    }
   ],
   "source": [
    "print(sample_t1)\n",
    "print(sample_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following three variations of `add()` are the same. Same for `sub()`, `mul()` and `div()`, etc..\n",
    "\n",
    "**Note**: these are *element-wise* operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6233,  1.4619,  0.6559],\n",
       "        [-0.3610, -0.9190, -0.8750]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t1 + sample_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6233,  1.4619,  0.6559],\n",
       "        [-0.3610, -0.9190, -0.8750]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t1.add(sample_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6233,  1.4619,  0.6559],\n",
       "        [-0.3610, -0.9190, -0.8750]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(sample_t1, sample_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0606,  0.4918, -2.1482],\n",
       "        [ 0.0252,  0.0516,  0.1911]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t1 * sample_t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_t3 = torch.randn(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.5662,  0.7001,  1.0126],\n",
       "        [ 0.2637, -0.3328,  1.5878],\n",
       "        [ 0.9340,  0.8332, -1.2957],\n",
       "        [-0.0796, -1.6718, -0.7158]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n",
      "tensor([2, 2, 1])\n",
      "tensor([2, 2, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(sample_t3.argmax())\n",
    "print(sample_t3.argmax(0))\n",
    "print(sample_t3.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5878)\n"
     ]
    }
   ],
   "source": [
    "print(sample_t3.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.9340, 0.8332, 1.5878]),\n",
       "indices=tensor([2, 2, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t3.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9340, 0.8332, 1.5878])\n",
      "tensor([2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "print(sample_t3.max(0).values)\n",
    "print(sample_t3.max(0).indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0126,  1.5878,  0.9340, -0.0796])\n",
      "tensor([2, 2, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(sample_t3.max(1).values)\n",
    "print(sample_t3.max(1).indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([ 1.0126,  1.5878,  0.9340, -0.0796]),\n",
      "indices=tensor([2, 2, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "print(sample_t3.max(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[-3.5662,  0.7001,  1.0126],\n",
       "        [-0.3328,  0.2637,  1.5878],\n",
       "        [-1.2957,  0.8332,  0.9340],\n",
       "        [-1.6718, -0.7158, -0.0796]]),\n",
       "indices=tensor([[0, 1, 2],\n",
       "        [1, 0, 2],\n",
       "        [2, 1, 0],\n",
       "        [1, 2, 0]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t3.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[-3.5662,  0.7001,  1.0126],\n",
       "        [-0.3328,  0.2637,  1.5878],\n",
       "        [-1.2957,  0.8332,  0.9340],\n",
       "        [-1.6718, -0.7158, -0.0796]]),\n",
       "indices=tensor([[0, 1, 2],\n",
       "        [1, 0, 2],\n",
       "        [2, 1, 0],\n",
       "        [1, 2, 0]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t3.sort(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[-3.5662, -1.6718, -1.2957],\n",
       "        [-0.0796, -0.3328, -0.7158],\n",
       "        [ 0.2637,  0.7001,  1.0126],\n",
       "        [ 0.9340,  0.8332,  1.5878]]),\n",
       "indices=tensor([[0, 3, 2],\n",
       "        [3, 1, 3],\n",
       "        [1, 0, 0],\n",
       "        [2, 2, 1]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t3.sort(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_t4 = torch.randn(3, 4)\n",
    "sample_t5 = torch.randn(4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three identical ways to perform matrix multiplication:\n",
    "- `a @ b`\n",
    "- `torch.mm(a, b)`\n",
    "- `a.mm(b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4109,  1.0740, -1.3934],\n",
       "        [ 1.2257, -0.0869,  0.3587],\n",
       "        [ 0.1282, -0.5011,  0.6057]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t4 @ sample_t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4109,  1.0740, -1.3934],\n",
       "        [ 1.2257, -0.0869,  0.3587],\n",
       "        [ 0.1282, -0.5011,  0.6057]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t4.mm(sample_t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4109,  1.0740, -1.3934],\n",
       "        [ 1.2257, -0.0869,  0.3587],\n",
       "        [ 0.1282, -0.5011,  0.6057]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(sample_t4, sample_t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For batches, we have to use `bmm` instead. Note that `@` operator is still valid for mini batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_t6 = torch.randn(2, 3, 4)\n",
    "sample_t7 = torch.randn(2, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-3.6460,  0.0383,  1.5289],\n",
      "         [-0.2309,  0.2930,  3.8853],\n",
      "         [-1.9953,  0.0478, -0.7433]],\n",
      "\n",
      "        [[ 0.3728, -0.1142, -0.9654],\n",
      "         [ 0.8009, -0.7652, -5.2539],\n",
      "         [-0.8692,  0.8701,  3.2773]]])\n",
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "_ = sample_t6.bmm(sample_t7)\n",
    "\n",
    "print(_)\n",
    "print(_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.6460,  0.0383,  1.5289],\n",
       "         [-0.2309,  0.2930,  3.8853],\n",
       "         [-1.9953,  0.0478, -0.7433]],\n",
       "\n",
       "        [[ 0.3728, -0.1142, -0.9654],\n",
       "         [ 0.8009, -0.7652, -5.2539],\n",
       "         [-0.8692,  0.8701,  3.2773]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(sample_t6, sample_t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.6460,  0.0383,  1.5289],\n",
       "         [-0.2309,  0.2930,  3.8853],\n",
       "         [-1.9953,  0.0478, -0.7433]],\n",
       "\n",
       "        [[ 0.3728, -0.1142, -0.9654],\n",
       "         [ 0.8009, -0.7652, -5.2539],\n",
       "         [-0.8692,  0.8701,  3.2773]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_t6 @ sample_t7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch matrix multiplication perform matrix multiplication on the last two dimensions. It is valid to perform `bmm` on more dimensions as long as the batch dimensions are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 2, 3, 5])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.randn(4, 2, 2, 3, 4) @ torch.randn(4, 2, 2, 4, 5)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contraction: Einstein Summation Convention\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.einsum.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"abc, acd -> abd\", torch.randn(2, 3, 4), torch.randn(2, 4, 5)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination and Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cat()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "cat(tensors, dim=0, *, out=None) -> Tensor\n",
      "\n",
      "Concatenates the given sequence of :attr:`seq` tensors in the given dimension.\n",
      "All tensors must either have the same shape (except in the concatenating\n",
      "dimension) or be empty.\n",
      "\n",
      ":func:`torch.cat` can be seen as an inverse operation for :func:`torch.split`\n",
      "and :func:`torch.chunk`.\n",
      "\n",
      ":func:`torch.cat` can be best understood via examples.\n",
      "\n",
      "Args:\n",
      "    tensors (sequence of Tensors): any python sequence of tensors of the same type.\n",
      "        Non-empty tensors provided must have the same shape, except in the\n",
      "        cat dimension.\n",
      "    dim (int, optional): the dimension over which the tensors are concatenated\n",
      "\n",
      "Keyword args:\n",
      "    out (Tensor, optional): the output tensor.\n",
      "\n",
      "Example::\n",
      "\n",
      "    >>> x = torch.randn(2, 3)\n",
      "    >>> x\n",
      "    tensor([[ 0.6580, -1.0969, -0.4614],\n",
      "            [-0.1034, -0.5790,  0.1497]])\n",
      "    >>> torch.cat((x, x, x), 0)\n",
      "    tensor([[ 0.6580, -1.0969, -0.4614],\n",
      "            [-0.1034, -0.5790,  0.1497],\n",
      "            [ 0.6580, -1.0969, -0.4614],\n",
      "            [-0.1034, -0.5790,  0.1497],\n",
      "            [ 0.6580, -1.0969, -0.4614],\n",
      "            [-0.1034, -0.5790,  0.1497]])\n",
      "    >>> torch.cat((x, x, x), 1)\n",
      "    tensor([[ 0.6580, -1.0969, -0.4614,  0.6580, -1.0969, -0.4614,  0.6580,\n",
      "             -1.0969, -0.4614],\n",
      "            [-0.1034, -0.5790,  0.1497, -0.1034, -0.5790,  0.1497, -0.1034,\n",
      "             -0.5790,  0.1497]])\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
     ]
    }
   ],
   "source": [
    "torch.cat??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(\n",
    "    tensors=[\n",
    "        torch.randn(3, 2), torch.randn(3, 3)\n",
    "    ], \n",
    "    dim=1\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(\n",
    "    tensors=[\n",
    "        torch.randn(4, 2), torch.randn(5, 2)\n",
    "    ]\n",
    ").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Stack()`:\n",
    "- Each tensor should have exact same shape\n",
    "- `dim` parameter will force the tensor to be stacked at a certain axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "stack(tensors, dim=0, *, out=None) -> Tensor\n",
      "\n",
      "Concatenates a sequence of tensors along a new dimension.\n",
      "\n",
      "All tensors need to be of the same size.\n",
      "\n",
      "Arguments:\n",
      "    tensors (sequence of Tensors): sequence of tensors to concatenate\n",
      "    dim (int): dimension to insert. Has to be between 0 and the number\n",
      "        of dimensions of concatenated tensors (inclusive)\n",
      "\n",
      "Keyword args:\n",
      "    out (Tensor, optional): the output tensor.\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
     ]
    }
   ],
   "source": [
    "torch.stack??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack expects each tensor to be equal size, but got [3, 2] at entry 0 and [5, 2] at entry 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.stack(\n",
    "        tensors=[\n",
    "            torch.randn(3, 2), torch.randn(5, 2)\n",
    "        ]\n",
    "    ).shape\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(\n",
    "    tensors=[\n",
    "        torch.randn(3, 4), torch.randn(3, 4)\n",
    "    ]\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(\n",
    "    tensors=[\n",
    "        torch.randn(3, 4), torch.randn(3, 4)\n",
    "    ],\n",
    "    dim=1\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(\n",
    "    tensors=[\n",
    "        torch.randn(3, 4), torch.randn(3, 4)\n",
    "    ],\n",
    "    dim=2\n",
    ").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"Splits the tensor into chunks. Each chunk is a view of the original tensor.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    If :attr:`split_size_or_sections` is an integer type, then :attr:`tensor` will\u001b[0m\n",
      "\u001b[0;34m    be split into equally sized chunks (if possible). Last chunk will be smaller if\u001b[0m\n",
      "\u001b[0;34m    the tensor size along the given dimension :attr:`dim` is not divisible by\u001b[0m\n",
      "\u001b[0;34m    :attr:`split_size`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    If :attr:`split_size_or_sections` is a list, then :attr:`tensor` will be split\u001b[0m\n",
      "\u001b[0;34m    into ``len(split_size_or_sections)`` chunks with sizes in :attr:`dim` according\u001b[0m\n",
      "\u001b[0;34m    to :attr:`split_size_or_sections`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m        tensor (Tensor): tensor to split.\u001b[0m\n",
      "\u001b[0;34m        split_size_or_sections (int) or (list(int)): size of a single chunk or\u001b[0m\n",
      "\u001b[0;34m            list of sizes for each chunk\u001b[0m\n",
      "\u001b[0;34m        dim (int): dimension along which to split the tensor.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Example::\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        >>> a = torch.arange(10).reshape(5,2)\u001b[0m\n",
      "\u001b[0;34m        >>> a\u001b[0m\n",
      "\u001b[0;34m        tensor([[0, 1],\u001b[0m\n",
      "\u001b[0;34m                [2, 3],\u001b[0m\n",
      "\u001b[0;34m                [4, 5],\u001b[0m\n",
      "\u001b[0;34m                [6, 7],\u001b[0m\n",
      "\u001b[0;34m                [8, 9]])\u001b[0m\n",
      "\u001b[0;34m        >>> torch.split(a, 2)\u001b[0m\n",
      "\u001b[0;34m        (tensor([[0, 1],\u001b[0m\n",
      "\u001b[0;34m                 [2, 3]]),\u001b[0m\n",
      "\u001b[0;34m         tensor([[4, 5],\u001b[0m\n",
      "\u001b[0;34m                 [6, 7]]),\u001b[0m\n",
      "\u001b[0;34m         tensor([[8, 9]]))\u001b[0m\n",
      "\u001b[0;34m        >>> torch.split(a, [1,4])\u001b[0m\n",
      "\u001b[0;34m        (tensor([[0, 1]]),\u001b[0m\n",
      "\u001b[0;34m         tensor([[2, 3],\u001b[0m\n",
      "\u001b[0;34m                 [4, 5],\u001b[0m\n",
      "\u001b[0;34m                 [6, 7],\u001b[0m\n",
      "\u001b[0;34m                 [8, 9]]))\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Overwriting reason:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# This dispatches to two ATen functions depending on the type of\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# split_size_or_sections. The branching code is in _tensor.py, which we\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# call here.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      /opt/anaconda3/envs/data-workspace/lib/python3.8/site-packages/torch/functional.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "torch.split??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "total_shape = (5, 13)\n",
    "split_len = 3\n",
    "dim = -1\n",
    "\n",
    "output_ = torch.split(\n",
    "    torch.randn(total_shape),\n",
    "    split_len,\n",
    "    dim\n",
    ")\n",
    "\n",
    "for v in output_:\n",
    "    print(v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`chunk()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "chunk(input, chunks, dim=0) -> List of Tensors\n",
      "\n",
      "Attempts to split a tensor into the specified number of chunks. Each chunk is a view of\n",
      "the input tensor.\n",
      "\n",
      "\n",
      ".. note::\n",
      "\n",
      "    This function may return less then the specified number of chunks!\n",
      "\n",
      ".. seealso::\n",
      "\n",
      "    :func:`torch.tensor_split` a function that always returns exactly the specified number of chunks\n",
      "\n",
      "If the tensor size along the given dimesion :attr:`dim` is divisible by :attr:`chunks`,\n",
      "all returned chunks will be the same size.\n",
      "If the tensor size along the given dimension :attr:`dim` is not divisible by :attr:`chunks`,\n",
      "all returned chunks will be the same size, except the last one.\n",
      "If such division is not possible, this function may return less\n",
      "than the specified number of chunks.\n",
      "\n",
      "Arguments:\n",
      "    input (Tensor): the tensor to split\n",
      "    chunks (int): number of chunks to return\n",
      "    dim (int): dimension along which to split the tensor\n",
      "\n",
      "Example::\n",
      "    >>> torch.arange(11).chunk(6)\n",
      "    (tensor([0, 1]),\n",
      "     tensor([2, 3]),\n",
      "     tensor([4, 5]),\n",
      "     tensor([6, 7]),\n",
      "     tensor([8, 9]),\n",
      "     tensor([10]))\n",
      "    >>> torch.arange(12).chunk(6)\n",
      "    (tensor([0, 1]),\n",
      "     tensor([2, 3]),\n",
      "     tensor([4, 5]),\n",
      "     tensor([6, 7]),\n",
      "     tensor([8, 9]),\n",
      "     tensor([10, 11]))\n",
      "    >>> torch.arange(13).chunk(6)\n",
      "    (tensor([0, 1, 2]),\n",
      "     tensor([3, 4, 5]),\n",
      "     tensor([6, 7, 8]),\n",
      "     tensor([ 9, 10, 11]),\n",
      "     tensor([12]))\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
     ]
    }
   ],
   "source": [
    "torch.chunk??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 7])\n",
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "total_shape = (5, 13)\n",
    "num_splits = 2\n",
    "dim = -1\n",
    "\n",
    "output_ = torch.chunk(\n",
    "    torch.randn(total_shape),\n",
    "    num_splits,\n",
    "    dim\n",
    ")\n",
    "\n",
    "for v in output_:\n",
    "    print(v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand, Squeeze and Broadcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 4])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4).unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4, 1).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1, 3, 4, 1).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1, 3, 4, 1).squeeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For *element-wise* operation, boardcast of a matrix can be utilized by `unsequeeze()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_t8 = torch.randn(2, 3, 4)\n",
    "sample_t9 = torch.randn(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sample_t8 + sample_t9\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample_t8 + sample_t9.unsqueeze(1)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, by default, the expanded tensor will be **broadcased** and repeated certain times to match the other tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9dcfe0f79b50cc5f3b107aa7d241d33d73837c5d7edc7d927c5b09bff6adf49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('data-workspace': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
